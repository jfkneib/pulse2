#!/usr/bin/python
#
# -*- coding: utf-8; -*-
#
# (c) 2007-2008 Mandriva, http://www.mandriva.com/
#
# $Id$
#
# This file is part of Pulse 2, http://pulse2.mandriva.org
#
# Pulse 2 is free software; you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation; either version 2 of the License, or
# (at your option) any later version.
#
# Pulse 2 is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with Pulse 2; if not, write to the Free Software
# Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston,
# MA 02110-1301, USA.

# Big modules
import os
import sys
import optparse
import time
import random

# Twisted
from twisted.internet import epollreactor
epollreactor.install()

import twisted.web.server
import twisted.internet.defer
import twisted.internet.base

# XMLRPC funcs
import pulse2.scheduler.scheduling
import pulse2.scheduler.network
import pulse2.scheduler.launcher
import pulse2.scheduler.launchers_driving

# Filter SA warns to prevent trivial (hex/dec notation) error printing on STDOUT
import warnings
warnings.filterwarnings("ignore", category=FutureWarning)

# Other stuff
from mmc.site import mmcconfdir
from pulse2.version import getVersion, getRevision
from pulse2.scheduler.config import SchedulerConfig, SchedulerDatabaseConfig
from pulse2.database.msc import MscDatabase
from pulse2.scheduler.assign_algo import MGAssignAlgoManager
from pulse2.scheduler.health import getHealth, checkStatus, startLoopTS, stopLoopTS, logLoopTS, preemptLoopTS
from pulse2.scheduler.tracking.preempt import Pulse2Preempt
from mmc.support.cache import LocMemCache

import pulse2.xmlrpc

# Logging
import logging
import logging.config

def get_next_delay(base, subject_to_incertitude = False):
    ret = base                  # next delay in "base" seconds,
    ret -= time.time() % base   # rounded to the lower (second modulo base)
    if subject_to_incertitude : # if we have to had some randomness, do it
        ret += random.random() * SchedulerConfig().incertitude_factor * base
    return ret

def start_all_callbacks():
    logger = logging.getLogger()
    logger.info('scheduler "%s": will start to run callbacks in %d seconds' % (SchedulerConfig().name, SchedulerConfig().initial_wait))
    time.sleep(SchedulerConfig().initial_wait)
    scheduleStartCommands()
    scheduleStopCommands()
    if SchedulerConfig().active_analyse_hour:
        scheduleAnalyseCommands()
    if SchedulerConfig().active_clean_states_stop:
        scheduleFixUnprocessedTasks()
    if SchedulerConfig().active_clean_states_run:
        scheduleFixProcessingTasks()
    scheduleLogStats()
    twisted.internet.reactor.callInThread(schedulePreemptStartedCommands)
    scheduleCheckStatus()
    logger.info('scheduler "%s": all callbacks started' % (SchedulerConfig().name))

def scheduleAnalyseCommands():
    """ periodicaly analyse commands """
    now = time.time() - time.altzone # fixes TZ glitch
    midnight_today = int(now / 86400) * 86400
    midnight_tomorrow = midnight_today + 86400

    hour_today = midnight_today + SchedulerConfig().analyse_hour
    hour_tomorrow = midnight_tomorrow + SchedulerConfig().analyse_hour

    if hour_today > now: # have to awake today
        analyse_commands_in = hour_today - now
    else: # will awake tomorrow
        analyse_commands_in = hour_tomorrow - now

    logging.getLogger().info('scheduler "%s": ANALYSE: Sleeping' % (SchedulerConfig().name))
    twisted.internet.reactor.callLater(analyse_commands_in, awakeAnalyseCommands)

def scheduleStartCommands():
    """ periodicaly starts commands """
    logging.getLogger().info('scheduler "%s": START: Sleeping' % (SchedulerConfig().name))
    startLoopTS.touch()
    twisted.internet.reactor.callLater(get_next_delay(SchedulerConfig().awake_time), awakeStartCommands)

def scheduleStopCommands():
    """ periodicaly stop commands (elapsed, etc ...) """
    logging.getLogger().info('scheduler "%s": STOP: Sleeping' % (SchedulerConfig().name))
    stopLoopTS.touch()
    twisted.internet.reactor.callLater(get_next_delay(SchedulerConfig().awake_time), awakeStopCommands)

def scheduleFixUnprocessedTasks():
    """ periodicaly see if running tasks (according to the DB) are still running """
    logging.getLogger().info('scheduler "%s": FUT: Sleeping' % (SchedulerConfig().name))
    twisted.internet.reactor.callLater(get_next_delay(SchedulerConfig().clean_states_time, True), awakeFixUnprocessedTasks)

def scheduleFixProcessingTasks():
    """ periodicaly see if not running tasks (according to the DB) are still running """
    logging.getLogger().info('scheduler "%s": FPT: Sleeping' % (SchedulerConfig().name))
    twisted.internet.reactor.callLater(get_next_delay(SchedulerConfig().clean_states_time, True), awakeFixProcessingTasks)

def schedulePreemptStartedCommands():
    """ periodicaly run commands marked to be run """
    preemptLoopTS.touch()
    twisted.internet.reactor.callLater(get_next_delay(SchedulerConfig().preempt_period), awakePreemptStartedCommands)

def scheduleLogStats():
    """ periodicaly log stats """
    logLoopTS.touch()
    twisted.internet.reactor.callLater(get_next_delay(SchedulerConfig().loghealth_period), awakeLogStats)

def scheduleCheckStatus():
    """ periodicaly check our status stats """
    logging.getLogger().debug('scheduler "%s": CHECK: Sleeping' % (SchedulerConfig().name)),
    twisted.internet.reactor.callLater(get_next_delay(SchedulerConfig().checkstatus_period, True), awakeCheckStatus)

def awakeAnalyseCommands():
    logging.getLogger().info('scheduler "%s": ANALYSE: Analysing database' % (SchedulerConfig().name))
    # as startAllCommands() may crash before giving a deferred (MySQL down for example),
    # we build a deferred chain
    try:
        d = pulse2.scheduler.scheduling.startAnalyseCommands(SchedulerConfig().name)
    except Exception, reason:
        logging.getLogger().error('scheduler "%s": ANALYSE: Before analysing database : %s' % (SchedulerConfig().name, pulse2.utils.extractExceptionMessage(reason)))
        scheduleAnalyseCommands()
        return
    d.addErrback(MscDatabase().antiPoolOverflowErrorback # self-explicit
    ).addCallbacks( # deferred handling
        lambda result: logging.getLogger().info('scheduler "%s": ANALYSE: Finished analysing database' % (SchedulerConfig().name)),
        lambda reason: logging.getLogger().error('scheduler "%s": ANALYSE: While analysing database : %s' % (SchedulerConfig().name, pulse2.utils.extractExceptionMessage(reason)))
    ).addBoth( # loop scheduling
        lambda nothing : scheduleAnalyseCommands() # lambda used to "silently" intercept return arg
    )

def awakeStartCommands():
    logging.getLogger().info('scheduler "%s": START: Analysing database' % (SchedulerConfig().name))

    try:
        commandsNumber = len(Pulse2Preempt().content)
        if commandsNumber > SchedulerConfig().preempt_amount:
            logging.getLogger().info('scheduler "%s": START: Before analysing database : %d commands are already in progress' % (SchedulerConfig().name, commandsNumber))
            scheduleStartCommands()
            return
        d = pulse2.scheduler.scheduling.startAllCommands(SchedulerConfig().name)
    except Exception, reason:
        logging.getLogger().error('scheduler "%s": START: Before analysing database : %s' % (SchedulerConfig().name, pulse2.utils.extractExceptionMessage(reason)))
        scheduleStartCommands()
        return
    d.addErrback(MscDatabase().antiPoolOverflowErrorback # self-explicit
    ).addCallbacks( # deferred handling
        lambda result: logging.getLogger().info('scheduler "%s": START: Finished analysing database' % (SchedulerConfig().name)),
        lambda reason: logging.getLogger().error('scheduler "%s": START: While analysing database : %s' % (SchedulerConfig().name, pulse2.utils.extractExceptionMessage(reason)))
    ).addBoth( # loop scheduling
        lambda nothing : scheduleStartCommands() # lambda used to "silently" intercept return arg
    )

def awakeStopCommands():
    logging.getLogger().info('scheduler "%s": STOP: Analysing database' % (SchedulerConfig().name))
    # as stopElapsedCommands() may crash before giving a deferred (MySQL down for example),
    # we build a deferred chain
    try:
        d = pulse2.scheduler.scheduling.stopElapsedCommands(SchedulerConfig().name)
    except Exception, reason:
        logging.getLogger().error('scheduler "%s": STOP: Before analysing database : %s' % (SchedulerConfig().name, pulse2.utils.extractExceptionMessage(reason)))
        scheduleStopCommands()
        return
    d.addErrback(MscDatabase().antiPoolOverflowErrorback # self-explicit
    ).addCallbacks( # deferred handling
        lambda result: logging.getLogger().info('scheduler "%s": STOP: Finished analysing database' % (SchedulerConfig().name)),
        lambda reason: logging.getLogger().error('scheduler "%s": STOP: While analysing database : %s' % (SchedulerConfig().name, pulse2.utils.extractExceptionMessage(reason)))
    ).addBoth( # loop scheduling
        lambda nothing : scheduleStopCommands() # lambda used to "silently" intercept return arg
    )

def awakeFixUnprocessedTasks():
    logging.getLogger().info('scheduler %s: FUT: Analysing database' % (SchedulerConfig().name))
    # as cleanStates() may crash before giving a deferred (MySQL down for example),
    # we build a deferred chain
    try:
        d = pulse2.scheduler.scheduling.fixUnprocessedTasks(SchedulerConfig().name)
    except Exception, reason:
        logging.getLogger().error('scheduler "%s": FUT: Before analysing database : %s' % (SchedulerConfig().name, pulse2.utils.extractExceptionMessage(reason)))
        scheduleFixUnprocessedTasks()
        return
    d.addErrback(MscDatabase().antiPoolOverflowErrorback # self-explicit
    ).addCallbacks( # deferred handling
        lambda result: logging.getLogger().info('scheduler "%s": FUT: Finished analysing database' % (SchedulerConfig().name)),
        lambda reason: logging.getLogger().error('scheduler "%s": FUT: While analysing database : %s' % (SchedulerConfig().name, pulse2.utils.extractExceptionMessage(reason)))
    ).addBoth( # loop scheduling
        lambda nothing : scheduleFixUnprocessedTasks() # lambda used to "silently" intercept return arg
    )
           
def awakeFixProcessingTasks():
    logging.getLogger().info('scheduler %s: FPT: Analysing database' % (SchedulerConfig().name))
    # as cleanStates() may crash before giving a deferred (MySQL down for example),
    # we build a deferred chain
    try:
        d = pulse2.scheduler.scheduling.fixProcessingTasks(SchedulerConfig().name)
    except Exception, reason:
        logging.getLogger().error('scheduler "%s": FPT: Before analysing database : %s' % (SchedulerConfig().name, pulse2.utils.extractExceptionMessage(reason)))
        scheduleFixProcessingTasks()
        return
    d.addErrback(MscDatabase().antiPoolOverflowErrorback # self-explicit
    ).addCallbacks( # deferred handling
        lambda result: logging.getLogger().info('scheduler "%s": FPT: Finished analysing database' % (SchedulerConfig().name)),
        lambda reason: logging.getLogger().error('scheduler "%s": FPT: While analysing database : %s' % (SchedulerConfig().name, pulse2.utils.extractExceptionMessage(reason)))
    ).addBoth( # loop scheduling
        lambda nothing : scheduleFixProcessingTasks()
    )

def awakePreemptStartedCommands():
    try:
        d = pulse2.scheduler.scheduling.preemptTasks(SchedulerConfig().name)
    except Exception, reason:
        logging.getLogger().error('scheduler "%s": PREEMPT/START: Before preempting : %s'  % (SchedulerConfig().name, pulse2.utils.extractExceptionMessage(reason)))
        schedulePreemptStartedCommands()
        return
    d.addErrback(MscDatabase().antiPoolOverflowErrorback # self-explicit
    # everything got commented out : logging is useless, it would burn space for nothing; see logging in preemptTasks
    #MDV/NR ).addCallbacks( # deferred handling
        #MDV/NR lambda result: logging.getLogger().info('scheduler "%s": PREEMPT/START: Finished preempting' % (SchedulerConfig().name)),
        #MDV/NR lambda reason: logging.getLogger().error('scheduler "%s": PREEMPT/START: While preempting : %s'  % (SchedulerConfig().name, pulse2.utils.extractExceptionMessage(reason)))
    ).addBoth( # loop scheduling
        lambda nothing : schedulePreemptStartedCommands() # lambda used to "silently" intercept return arg
    )

def awakeLogStats():
    logging.getLogger().info('scheduler %s: HEALTH: %s' % (SchedulerConfig().name, getHealth()))
    scheduleLogStats()

def awakeCheckStatus():
    logging.getLogger().debug('scheduler %s: CHECK: Starting' % (SchedulerConfig().name))
    checkStatus()
    scheduleCheckStatus()

def startService():
    logger = logging.getLogger()
    config = SchedulerConfig()
    if not config.username:
        logger.warn('scheduler %s: no username set !!' % (config.name))
    if not config.password:
        logger.warn('scheduler %s: no password set !!' % (config.name))
    # check versus MySQLdb version
    import MySQLdb
    (v1, v2, v3, v4, v5) = MySQLdb.version_info
    force_ascii = False
    warn_debian = False
    if v1 == 1: # handle v. 1.x
        if v2 <= 1: # handle of v. 1.0.x and 1.1.x
            force_ascii = True
            warn_debian = True
        elif v2 == 2: # handle of v. 1.2.x
            if v3 == 0: # handling of v. 1.2.0.x
                force_ascii = True
                warn_debian = True
            if v3 == 1: # handling of v. 1.2.1.x
                warn_debian = True
                if v4 != 'final': # versions up to 1.2.1c??? are buggy => inject using ascii convertion
                    force_ascii = True
            if v3 == 2: # handling of v. 1.2.2.x
                warn_debian = True

    if force_ascii :
        logger.warn('scheduler "%s": python-mysqldb too old (spotted %s), using "ascii" as db encoding' % (config.name, MySQLdb.version_info))
        config.dbencoding = 'ascii'

    if warn_debian :
        import platform
        try :
            (p,v,i) = platform.dist()
            if p == 'debian' :
                logger.warn('scheduler "%s": Please make sure that your python-mysql package is at least 1.2.2-7; on Debian-based platforms previous versions are buggy (broken auto-reconnect), see http://packages.debian.org/changelogs/pool/main/p/python-mysqldb/python-mysqldb_1.2.2-7/changelog#versionversion1.2.2-7' % (config.name))
        except :
            pass

    launchers = map(lambda(a): 'xml://%s:%s' % (config.launchers[a]['host'], config.launchers[a]['port']), config.launchers)
    logger.info('scheduler %s: available launchers: %s' % (config.name, ' '.join(launchers)))

    # put the machine to command group algorithm
    MGAssignAlgoManager().setAlgo(config.mg_assign_algo)

    # Set cache
    cache = LocMemCache()
    cache.init(timeout=SchedulerConfig().cache_timeout,
               max_entries=SchedulerConfig().cache_size)

    pref_ntw_display = [(ip +"/"+ mask) for ip, mask in config.preferred_network]
    logger.info("Preferred network is set to %s" % str(pref_ntw_display))


    twisted.internet.reactor.callWhenRunning(start_all_callbacks)
    twisted.internet.reactor.addSystemEventTrigger('before', 'shutdown', cleanUp)
    if config.multithreading:
        logger.info('scheduler %s: setting threadpool max size to %d' % (config.name, config.max_threads))
        twisted.internet.reactor.suggestThreadPoolSize(config.max_threads)
    logger.info('scheduler %s: listening on %s:%d' % (config.name, config.host, config.port))
    twisted.internet.reactor.run()
    return 0

def cleanUp():
    logger = logging.getLogger()
    logger.info('scheduler %s: Shutting down and cleaning up' % (SchedulerConfig().name))
    logger.info('scheduler %s: End' % (SchedulerConfig().name))


def main():
    parser = optparse.OptionParser()
    parser.add_option("-c", "--config-file", help='path to the config file', default=mmcconfdir + '/pulse2/scheduler/scheduler.ini')
    (options, args) = parser.parse_args()

    if not os.path.exists(options.config_file):
        print "Config file '%s' does not exist." % options.config_file
        sys.exit(3)

    # start logger
    logging.config.fileConfig(options.config_file)
    logger = logging.getLogger()
    logger.info("Scheduler version('%s') build('%s')" % (str(getVersion()), str(getRevision())))

    # parse conf
    logger.info("Reading configuration file: %s" % options.config_file)
    try:
        SchedulerConfig().setup(options.config_file)
    except Exception, e:
        logger.error(e)
        logger.error("Please fix the configuration file")
        sys.exit(1)

    try:
        confmsc = SchedulerDatabaseConfig()
        confmsc.setup(options.config_file)
        if not MscDatabase().activate(confmsc): # does the db_check
            sys.exit(1)
    except Exception, e:
        logger.error(e)
        logger.error("Please fix the configuration file")
        sys.exit(1)

    # start service
    sys.exit(startService())

if __name__ == '__main__':
    main()
